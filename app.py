import base64
import binascii
import io
import os
from datetime import datetime
from typing import Optional

from flask import Flask, render_template, request, jsonify, send_file
from dotenv import load_dotenv
import requests
from docx import Document
from docx.shared import Inches

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

app = Flask(__name__, template_folder='templates')

# OpenAI API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_URL = "https://api.openai.com/v1/responses"


def _normalize_content_parts(content_parts):
    """Convert legacy chat-completions content parts into Responses API format."""
    normalized = []
    if not isinstance(content_parts, list):
        return normalized

    for part in content_parts:
        if not isinstance(part, dict):
            continue

        part_type = part.get("type")

        if part_type in {"text", "input_text"}:
            text_value = part.get("text")
            if isinstance(text_value, str):
                normalized.append({"type": "input_text", "text": text_value})
            continue

        if part_type in {"image_url", "input_image"}:
            image_url = part.get("image_url")
            if isinstance(image_url, dict):
                url_value = image_url.get("url")
            else:
                url_value = image_url
            if isinstance(url_value, str) and url_value:
                normalized.append({"type": "input_image", "image_url": url_value})
            continue

        # Passthrough any already-normalized content blocks.
        if part_type in {"input_audio", "input_video", "input_file"}:
            normalized.append(part)

    if not normalized:
        for part in content_parts:
            if isinstance(part, dict):
                normalized.append(part)

    return normalized


def _extract_text_from_response(response_payload):
    """Pull a best-effort assistant text string from a Responses API payload."""
    if not isinstance(response_payload, dict):
        return ""

    output_text = response_payload.get("output_text")
    if isinstance(output_text, str) and output_text.strip():
        return output_text

    collected = []
    output_items = response_payload.get("output")
    if isinstance(output_items, list):
        for item in output_items:
            if not isinstance(item, dict):
                continue
            if item.get("type") != "message":
                continue
            contents = item.get("content") or []
            if not isinstance(contents, list):
                continue
            for content in contents:
                if not isinstance(content, dict):
                    continue
                text_value = content.get("text")
                if isinstance(text_value, str) and text_value:
                    collected.append(text_value)

    if collected:
        return "\n".join(collected)

    # Fallback: if the upstream response still uses chat-completions layout, read it.
    choices = response_payload.get("choices")
    if isinstance(choices, list) and choices:
        first_choice = choices[0]
        if isinstance(first_choice, dict):
            message = first_choice.get("message")
            if isinstance(message, dict):
                content = message.get("content")
                if isinstance(content, str):
                    return content

    return ""

@app.route('/')
def index():
    """ë©”ì¸ ì›¹í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    """
    í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° ìš”ì²­ì„ ë°›ì•„ OpenAI APIë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not API_KEY:
        print("ğŸ›‘ ì˜¤ë¥˜: .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return jsonify({"error": ".env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500

    data = request.json
    
    content_parts = data.get("content_parts", [])
    normalized_content = _normalize_content_parts(content_parts)

    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ OpenAIì— ë³´ë‚¼ payloadë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    requested_model = data.get("model", "gpt-5-mini")
    model_presets = {
        "gpt-5-mini": {
            "max_output_tokens": 4096,
            "temperature": 0.2,
            "top_p": 0.8,
        },
        "gpt-4o": {
            "max_output_tokens": 3072,
            "temperature": 0.6,
            "top_p": 0.9,
        },
    }

    if requested_model not in model_presets:
        print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤: {requested_model}. gpt-5-minië¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")

    model = requested_model if requested_model in model_presets else "gpt-5-mini"
    model_payload_options = model_presets[model]

    payload = {
        # gpt-5-miniëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ URLì´ í˜¼í•©ëœ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì…ë‹ˆë‹¤.
        "model": model,
        "input": [{
            "role": "user",
            "content": normalized_content,
        }],
        **model_payload_options,
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}",
    }

    try:
        print(
            "ğŸš€ OpenAI APIì— ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤... "
            f"(model={model}, temperature={model_payload_options['temperature']}, "
            f"max_output_tokens={model_payload_options['max_output_tokens']}, top_p={model_payload_options['top_p']})"
        )
        response = requests.post(OPENAI_API_URL, headers=headers, json=payload)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        print("âœ… OpenAI APIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
        response_payload = response.json()
        analysis_text = _extract_text_from_response(response_payload)
        return jsonify({
            "choices": [{"message": {"content": analysis_text}}],
            "raw_response": response_payload,
        })
        
    except requests.exceptions.RequestException as e:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        error_message = str(e)
        if e.response:
            try:
                error_detail = e.response.json()
                error_message = error_detail.get("error", {}).get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            except ValueError:
                error_message = e.response.text
        
        print(f"ğŸ›‘ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {error_message}")
        return jsonify({"error": f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {error_message}"}), 500


def _decode_data_url(data_url: Optional[str]) -> Optional[bytes]:
    """Decode a base64 data URL into raw bytes."""
    if not data_url or not data_url.startswith("data:"):
        return None
    try:
        header, encoded = data_url.split(",", 1)
    except ValueError:
        return None
    if ";base64" not in header:
        return None
    try:
        return base64.b64decode(encoded)
    except (binascii.Error, ValueError):
        return None


def _sanitize_filename(filename: str) -> str:
    base_name = filename.rsplit('.', 1)[0]
    safe = ''.join(ch for ch in base_name if ch.isalnum() or ch in (' ', '_', '-')).strip()
    return safe or "analysis_report"


@app.route('/create-report', methods=['POST'])
def create_report():
    if not request.is_json:
        return jsonify({"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ í˜•ì‹ì…ë‹ˆë‹¤. JSON ë°ì´í„°ë¥¼ ì „ì†¡í•´ì£¼ì„¸ìš”."}), 400

    payload = request.get_json(silent=True) or {}
    title = payload.get("title", "ë³´ê³ ì„œ")
    global_summary = payload.get("global_summary", "")
    analysis_results = payload.get("analysis_results", [])
    if not isinstance(analysis_results, list):
        analysis_results = []

    document = Document()

    document.add_heading(title.replace('.pdf', ''), level=0)
    document.add_paragraph(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    document.add_page_break()
    document.add_heading("Executive Summary", level=1)
    for line in str(global_summary).split('\n'):
        document.add_paragraph(line)

    document.add_page_break()
    document.add_heading("ìƒì„¸ ë¶„ì„ (Detailed Analysis)", level=1)

    for index, result in enumerate(analysis_results, start=1):
        group = result.get("group") if isinstance(result, dict) else {}
        if not isinstance(group, dict):
            group = {}
        group_id = group.get("id", index)
        pages = group.get("pages") or []
        pages_text = ", ".join(str(page) for page in pages) if pages else "N/A"
        document.add_heading(f"ê·¸ë£¹ {group_id} (í˜ì´ì§€: {pages_text})", level=2)

        intent = group.get("intent", "")
        intent_paragraph = document.add_paragraph()
        intent_run = intent_paragraph.add_run("ë¶„ì„ ì´ˆì : ")
        intent_run.bold = True
        intent_paragraph.add_run(str(intent))

        images = result.get("images") if isinstance(result, dict) else []
        for image_data_url in images or []:
            image_bytes = _decode_data_url(image_data_url)
            if not image_bytes:
                continue
            image_stream = io.BytesIO(image_bytes)
            try:
                document.add_picture(image_stream, width=Inches(6))
            except Exception as picture_error:  # pylint: disable=broad-except
                document.add_paragraph(f"[ì´ë¯¸ì§€ ì¶”ê°€ ì‹¤íŒ¨: {picture_error}]")

        analysis_text = result.get("analysis", "") if isinstance(result, dict) else ""
        for line in str(analysis_text).split('\n'):
            document.add_paragraph(line)

        document.add_paragraph()

    buffer = io.BytesIO()
    document.save(buffer)
    buffer.seek(0)

    filename = f"{_sanitize_filename(str(title))}_analysis_report.docx"

    return send_file(
        buffer,
        as_attachment=True,
        download_name=filename,
        mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    )

if __name__ == '__main__':
    port = 5001
    print(f"âœ… ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. http://127.0.0.1:{port} ì—ì„œ ì ‘ì†í•˜ì„¸ìš”.")
    app.run(debug=True, port=port)
